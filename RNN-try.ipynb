{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN(\n",
      "  (rnn): RNN(26, 128, num_layers=3, batch_first=True)\n",
      "  (out): Linear(in_features=128, out_features=26, bias=True)\n",
      ")\n",
      "_________________________________________________________________\n",
      "\n",
      "loss: 3.2695363    accuracy: 0.038461538461538464 \n",
      "\n",
      "_________________________________________________________________\n",
      "\n",
      "loss: 0.42689097    accuracy: 1.0 \n",
      "\n",
      "_________________________________________________________________\n",
      "\n",
      "loss: 0.08628748    accuracy: 1.0 \n",
      "\n",
      "_________________________________________________________________\n",
      "\n",
      "loss: 0.038664218    accuracy: 1.0 \n",
      "\n",
      "_________________________________________________________________\n",
      "\n",
      "loss: 0.02256941    accuracy: 1.0 \n",
      "\n",
      "_________________________________________________________________\n",
      "\n",
      "loss: 0.0149557255    accuracy: 1.0 \n",
      "\n",
      "_________________________________________________________________\n",
      "\n",
      "loss: 0.010681391    accuracy: 1.0 \n",
      "\n",
      "_________________________________________________________________\n",
      "\n",
      "loss: 0.008019231    accuracy: 1.0 \n",
      "\n",
      "_________________________________________________________________\n",
      "\n",
      "loss: 0.0062351376    accuracy: 1.0 \n",
      "\n",
      "_________________________________________________________________\n",
      "\n",
      "loss: 0.0049744477    accuracy: 1.0 \n",
      "\n",
      "_________________________________________________________________\n",
      "\n",
      "loss: 0.0040480513    accuracy: 1.0 \n",
      "\n",
      "_________________________________________________________________\n",
      "\n",
      "loss: 0.0033461484    accuracy: 1.0 \n",
      "\n",
      "_________________________________________________________________\n",
      "\n",
      "loss: 0.0028013068    accuracy: 1.0 \n",
      "\n",
      "_________________________________________________________________\n",
      "\n",
      "loss: 0.0023696946    accuracy: 1.0 \n",
      "\n",
      "_________________________________________________________________\n",
      "\n",
      "loss: 0.0020218997    accuracy: 1.0 \n",
      "\n",
      "_________________________________________________________________\n",
      "\n",
      "loss: 0.0017377393    accuracy: 1.0 \n",
      "\n",
      "_________________________________________________________________\n",
      "\n",
      "loss: 0.0015027113    accuracy: 1.0 \n",
      "\n",
      "_________________________________________________________________\n",
      "\n",
      "loss: 0.0013063862    accuracy: 1.0 \n",
      "\n",
      "_________________________________________________________________\n",
      "\n",
      "loss: 0.0011408324    accuracy: 1.0 \n",
      "\n",
      "_________________________________________________________________\n",
      "\n",
      "loss: 0.0010001758    accuracy: 1.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import math\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# torch.manual_seed(1)    # reproducible\n",
    "\n",
    "# Hyper Parameters\n",
    "TIME_STEP = 26      # rnn time step\n",
    "INPUT_SIZE = 26      # rnn input size\n",
    "LR = 0.0001           # learning rate\n",
    "\n",
    "# show data\n",
    "# steps = np.linspace(0, np.pi*2, 100, dtype=np.float32)  # float32 for converting torch FloatTensor\n",
    "# x_np = np.sin(steps)\n",
    "# y_np = np.cos(steps)\n",
    "# plt.plot(steps, y_np, 'r-', label='target (cos)')\n",
    "# plt.plot(steps, x_np, 'b-', label='input (sin)')\n",
    "# plt.legend(loc='best')\n",
    "# plt.show()\n",
    "\n",
    "pre = [[0 for j in range(0,26)] for i in range(0,26)]\n",
    "x = []\n",
    "y = [(i+1)%26 for i in range(0,26)]\n",
    "for i in range(0,26):\n",
    "    x.append([])\n",
    "    for j in range(0,26):\n",
    "        x[i].append(0)\n",
    "        if i == j:\n",
    "            x[i][j] = 1\n",
    "\n",
    "x = torch.from_numpy(np.array(x).reshape((-1,TIME_STEP,INPUT_SIZE))).float()\n",
    "y = torch.from_numpy(np.array(y).reshape((-1,INPUT_SIZE))).long()\n",
    "# print(x)\n",
    "\n",
    "# print(x.shape, \"\\n\", y.shape)\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.rnn = nn.RNN(\n",
    "            input_size=INPUT_SIZE,\n",
    "            hidden_size=128,     # rnn hidden unit\n",
    "            num_layers=3,       # number of rnn layer\n",
    "            batch_first=True,   # input & output will has batch size as 1s dimension. e.g. (batch, time_step, input_size)\n",
    "        )\n",
    "        self.out = nn.Linear(128, 26)\n",
    "\n",
    "    def forward(self, x, h_state):\n",
    "        # x (batch, time_step, input_size)\n",
    "        # h_state (n_layers, batch, hidden_size)\n",
    "        # r_out (batch, time_step, output_size)\n",
    "        r_out, h_state = self.rnn(x, h_state)\n",
    "\n",
    "        outs = []    # save all predictions\n",
    "        for time_step in range(r_out.size(1)):    # calculate output for each time step\n",
    "            outs.append(self.out(r_out[:, time_step, :]))\n",
    "        return torch.stack(outs, dim=1), h_state\n",
    "\n",
    "        # instead, for simplicity, you can replace above codes by follows\n",
    "        # r_out = r_out.view(-1, 32)\n",
    "        # outs = self.out(r_out)\n",
    "        # outs = outs.view(-1, TIME_STEP, 1)\n",
    "        # return outs, h_state\n",
    "        \n",
    "        # or even simpler, since nn.Linear can accept inputs of any dimension \n",
    "        # and returns outputs with same dimension except for the last\n",
    "        # outs = self.out(r_out)\n",
    "        # return outs\n",
    "\n",
    "rnn = RNN()\n",
    "print(rnn)\n",
    "\n",
    "optimizer = torch.optim.Adam(rnn.parameters(), lr=LR)   # optimize all cnn parameters\n",
    "loss_func = nn.CrossEntropyLoss()  \n",
    "\n",
    "h_state = None      # for initial hidden state\n",
    "\n",
    "# plt.figure(1, figsize=(12, 5))\n",
    "# plt.ion()           # continuously plot\n",
    "\n",
    "for i in range(4000):\n",
    "    prediction,h_state = rnn(x, h_state)\n",
    "    h_state = h_state.data\n",
    "#     print(prediction.size())\n",
    "    loss = loss_func(prediction[0], y[0])\n",
    "    optimizer.zero_grad()                   # clear gradients for this training step\n",
    "    loss.backward()                         # backpropagation, compute gradients\n",
    "    optimizer.step()                        # apply gradients\n",
    "    if(i % 200 == 0):\n",
    "        prediction_index = torch.argmax(prediction,2)\n",
    "#         print(prediction_index)\n",
    "        accuracy = float((prediction_index == y).sum())/26\n",
    "        print(\"_________________________________________________________________\\n\")\n",
    "        print(\"loss:\", loss.data.numpy(), \"   accuracy:\", accuracy, \"\\n\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
